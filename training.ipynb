{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm \n",
    "from datasets import load_from_disk, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import  TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import wandb\n",
    "\n",
    "from src.data.preprocess import DatasetProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # --- Categoria 1: Veloci e Bilanciati (Ottimi per baseline) ---\n",
    "# modelli_veloci = [\n",
    "#     \"resnet18\",\n",
    "#     \"resnet34\",\n",
    "#     \"resnet50\",\n",
    "#     \"efficientnet_b0\",\n",
    "#     \"efficientnet_b1\",\n",
    "#     \"mobilenetv3_large_100\",\n",
    "# ]\n",
    "\n",
    "# # --- Categoria 2: Alte Prestazioni (Per massima accuratezza) ---\n",
    "# modelli_performanti = [\n",
    "#     \"efficientnetv2_s\",\n",
    "#     \"efficientnetv2_m\",\n",
    "#     \"convnext_tiny\",\n",
    "#     \"convnext_small\",\n",
    "#     \"maxvit_tiny_tf_224\",\n",
    "# ]\n",
    "\n",
    "# # --- Categoria 3: Vision Transformers (Architetture basate su Attention) ---\n",
    "# modelli_transformer = [\n",
    "#     \"vit_small_patch16_224\",\n",
    "#     \"vit_base_patch16_224\",\n",
    "#     \"swin_tiny_patch4_window7_224\",\n",
    "#     \"swin_small_patch4_window7_224\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18\"\n",
    "pretrained = True\n",
    "\n",
    "DATASET_PATH = \"/home/vcivale/GenomicVision/data/interim\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54016d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 50\n",
    "OUTPUT_DIR = \"/equilibrium/datasets/TCGA-histological-data/genomic_vision/results\"\n",
    "\n",
    "# W&B\n",
    "WANDB_PROJECT = \"genomic-vision\"\n",
    "WANDB_RUN_NAME = f\"{model_name}_pretrained_{pretrained}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=pretrained,\n",
    "        in_chans=4,\n",
    "        num_classes=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processor = DatasetProcessor(model_name=model_name, in_channels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_from_disk(DATASET_PATH)\n",
    "\n",
    "# Ensure raw_dataset is a DatasetDict\n",
    "if not isinstance(raw_dataset, DatasetDict):\n",
    "    raw_dataset = DatasetDict({'train': raw_dataset})\n",
    "\n",
    "# dataset = dataset_processor.process_dataset(raw_dataset)\n",
    "dataset = raw_dataset\n",
    "\n",
    "train_val = dataset['train'].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_val['train'],\n",
    "    'validation': train_val['test'],\n",
    "    'test': dataset['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=500,\n",
    "        \n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=50,\n",
    "        save_total_limit=2,\n",
    "        \n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        \n",
    "        dataloader_num_workers=0,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=WANDB_RUN_NAME,\n",
    "        dataloader_drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae454fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=dataset['train'],\n",
    "        eval_dataset=dataset['validation'],\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4696ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = trainer.evaluate(dataset['test'], metric_key_prefix=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
